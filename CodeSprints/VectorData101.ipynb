{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/LizCarter492/EnvDatSci/blob/main/CodeSprints/VectorData101.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wy65tB7NAWRy"
   },
   "source": [
    "# Spatial Vector Data in Python w/ Geopandas\n",
    "You will use the geopandas library to work with vector data in Python. Geopandas is built on top of the Python Pandas library. It stores spatial data in a tabular, dataframe format.\n",
    "\n",
    "This notebook will take you through [Lesson 3 in Introductory Earth Data Science](https://www.earthdatascience.org/courses/intro-to-earth-data-science/file-formats/use-spatial-data/use-vector-data/) with some additional exercises from the [Geopandas project page](https://geopandas.org/en/v0.8.2/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AoZASwHLwpAS"
   },
   "source": [
    "# Sync your colab environment with your Google Drive and GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n63jAsimAWR1"
   },
   "outputs": [],
   "source": [
    "#attach to Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WmOwykNxwvL1"
   },
   "source": [
    "# The Code Sprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9KyeM4C89orB"
   },
   "outputs": [],
   "source": [
    "!pip install geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xgMUKEkJLmB6"
   },
   "outputs": [],
   "source": [
    "!pip install earthpy\n",
    "!pip install rtree\n",
    "!pip install pygeos\n",
    "!pip install mapclassify>=2.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fxgQBbU3Oxbl"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import earthpy as et\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5sE97xoBAWR4"
   },
   "source": [
    "To begin, set your working directory to earth-analytics and then download a single shapefile.\n",
    "\n",
    "You will start with working with the Natural Earth country boundary lines layer: https://www.naturalearthdata.com/downloads/\n",
    "\n",
    "Note that below you are using EarthPy to download a dataset from naturalearthdata.com (via Amazon Web Services).\n",
    "\n",
    "EarthPy automatically creates the earth-analytics directory for you when you use it, but by default makes this directory in your home directory. We're doing this here because you guys are on PCs.\n",
    "\n",
    "You set the working directory after you download the data as a precaution to ensure that the earth-analytics directory already exists on your computer. This is not a standard order of operations, as we are not using our SU H drive, but we are demonstrating it here to ensure the notebook runs on all computers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HX73ilrbAWR5"
   },
   "outputs": [],
   "source": [
    "# Download a political boundaries shapefile and set your working directory\n",
    "et.data.get_data(\n",
    "    url='https://naturalearth.s3.amazonaws.com/50m_cultural/ne_50m_admin_0_boundary_lines_land.zip')\n",
    "\n",
    "# Set working directory - earthpy creates earth-analytics for you in your home dir\n",
    "os.chdir(os.path.join(et.io.HOME, 'earth-analytics'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p1FhqaeJAWR5"
   },
   "source": [
    "### geopandas\n",
    "Next, you open the data using geopandas.\n",
    "\n",
    "***geopandas*** takes all of the data science magic from the pandas library and makes it compatible with shapfiles.\n",
    "\n",
    "Learn more here: https://geopandas.org/\n",
    "\n",
    "You can view the first 5 rows of the data using .head() in the same way you used .head() for Pandas dataframes.¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "daU0NJvsAWR6"
   },
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cNBjUKF1AWR7"
   },
   "source": [
    "We're going to download a second dataset, called coastlines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "im1CUtUbAWR8"
   },
   "outputs": [],
   "source": [
    "#set URL for the dataset\n",
    "coastlines_url = \"https://naturalearth.s3.amazonaws.com/50m_physical/ne_50m_coastline.zip\"\n",
    "\n",
    "#download the URL into your earth-analytics folder\n",
    "et.data.get_data(url=coastlines_url)\n",
    "\n",
    "#name the filepath relative to your working directory: note this is operating system agnostic\n",
    "coastlines_path = os.path.join(\"data\", \"earthpy-downloads\",\n",
    "                               \"ne_50m_coastline\",\n",
    "                               \"ne_50m_coastline.shp\")\n",
    "\n",
    "#use geopandas as gpd to \"read_file\"\n",
    "coastlines = gpd.read_file(coastlines_path)\n",
    "\n",
    "#prints \"head\" just like pandas!\n",
    "coastlines.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AWVggDwWAWR9"
   },
   "source": [
    "## GeoPandas creates GeoDataFrames\n",
    "The structure of a Geopandas GeoDataFrame is very similar to a Pandas dataframe. This means that all the awesome data wrangling functionality of pandas dataframes can be applied to our spatial vector data as well.\n",
    "\n",
    "### A few differences include:\n",
    "The GeoDataFrame contains a geometry column which stores spatial information. The geometry column in your GeoDataFrame stores the boundary information (the lines that make up each shape in your data). This allows you to plot points, lines or polygons.\n",
    "\n",
    "The GeoDataFrame stores spatial attributes such as coordinate reference systems and spatial extents.\n",
    "\n",
    "Similar to Pandas, you can plot the data using .plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wf3hUYvnAWR-"
   },
   "outputs": [],
   "source": [
    "# Plot the data\n",
    "f, ax1 = plt.subplots(figsize=(12, 6))\n",
    "coastlines.plot(ax=ax1)\n",
    "\n",
    "# Add a title to your plot\n",
    "ax1.set(title=\"Global Coastline Boundaries\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YiF7ytzZAWR_"
   },
   "source": [
    "### Check the Spatial Vector Data Type\n",
    "You can look at the data to figure out what type of data are stored in the shapefile (points, line or polygons). However, you can also get that information by calling .geom_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xw9ujP22AWR_"
   },
   "outputs": [],
   "source": [
    "# Is the geometry type point, line or polygon?\n",
    "coastlines.geom_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Z3XseEqAWSA"
   },
   "source": [
    "Also similar to Pandas, you can view descriptive information about the GeoDataFrame using .info(). This includes the number of columns, rows and the header name and type of each column.¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZMNnZaOUAWSB"
   },
   "outputs": [],
   "source": [
    "coastlines.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v6t7ulmJAWSC"
   },
   "source": [
    "### Open point data\n",
    "Next, you will accesss another online shapefile using Geopandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XMCHAAnXAWSC"
   },
   "outputs": [],
   "source": [
    "# Open a second layer\n",
    "et.data.get_data(\n",
    "    url='https://naturalearth.s3.amazonaws.com/50m_cultural/ne_50m_populated_places_simple.zip')\n",
    "\n",
    "# Create a path to the populated places shapefile\n",
    "populated_places_path = os.path.join(\"data\", \"earthpy-downloads\",\n",
    "                                     \"ne_50m_populated_places_simple\",\n",
    "                                     \"ne_50m_populated_places_simple.shp\")\n",
    "\n",
    "#read in a new geopandas data frame called \"cities\"\n",
    "cities = gpd.read_file(populated_places_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cuHhWHjiAWSD"
   },
   "source": [
    "### TASK 1: Is cities a point, line, or polygon file? Type a command to find out and interpret the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e6BEiY2ZAWSD"
   },
   "outputs": [],
   "source": [
    "# Task 1 answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lWs792nPAWSD"
   },
   "source": [
    "The attributes for a shapefile imported into a GeoDataFrame can be viewed in the GeoDataFrame itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zU47qq6jAWSD"
   },
   "outputs": [],
   "source": [
    "# View first 5 rows of GeoDataFrame\n",
    "cities.head()\n",
    "\n",
    "\n",
    "# Experiment! How would you view the first 10 rows of a GeoDataFrame?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_4zDORD5AWSE"
   },
   "source": [
    "Just like with Pandas DataFrames, standard arguments can be used to calculate summary statistics on your GeoPandas object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nZlzvjoVAWSE"
   },
   "outputs": [],
   "source": [
    "#Let's see what our most populous city is\n",
    "#print out the column with maximum population\n",
    "print(cities.pop_max)\n",
    "print(cities.iloc[cities.pop_max.idxmax()])\n",
    "\n",
    "print(\"The world's largest city  by population is \" + cities.name.iloc[cities.pop_max.idxmax()] +\n",
    "      \" with \" + str(cities.pop_max.max()) +\n",
    "      \" people!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bD4altg7ZcY6"
   },
   "source": [
    "## Geopandas = geographic pandas data frames\n",
    "The handy thing about working with vector data in geopandas is that you have all of the functionality of pandas at your fingertips. This means that it is easy to do things like:\n",
    "1. Subset your shapefile based on certain crtiera\n",
    "2. Merge your shapefile with other datasets\n",
    "3. Process fields (columns) in your shapefile using python commands.\n",
    "\n",
    "For example, let's say we are conducting a study on megacities. We can easily identify our megacities using the pop_max field, and use that to create a new geopandas DataFrame of only megacities (cities with a population greater than 10 million."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RgmN45l7X9x-"
   },
   "outputs": [],
   "source": [
    "megacities = cities[cities.pop_max >= 10000000]\n",
    "print(megacities)\n",
    "type(megacities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fsIQrDG7AWSF"
   },
   "source": [
    "### Creating Maps Using Multiple Shapefiles\n",
    "You can create maps using multiple shapefiles with Geopandas in a similar way that you may do so using a graphical user interface (GUI) tool like ArcGIS or QGIS (open source alternative to ArcGIS). To do this you will need to open a second spatial file. Below you will use the Natural Earth populated places shapefile to add additional layers to your map.\n",
    "\n",
    "To plot two datasets together, you will first create a Matplotlib figure object. Notice in the example below that you define the figure ax1 in the first line. You then tell GeoPandas to plot the data on that particular figure using the parameter ax=\n",
    "\n",
    "The code looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sbKWWShmAWSF"
   },
   "outputs": [],
   "source": [
    "#Experiment!\n",
    "#What happens if you change FigSize numbers?\n",
    "#What happens if you \"comment out\" (put a # in front of) plt.show()?\n",
    "#What happens if you change the color?\n",
    "\n",
    "f, ax1 = plt.subplots(figsize=(10, 6))\n",
    "coastlines.plot(ax=ax1,\n",
    "               color = \"black\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RMXUgNKcAWSG"
   },
   "source": [
    "To add another layer to your map, you can add a second .plot() call and specify the ax= to be ax1 again. This tells Python to layer the two datasets in the same figure. Identify the lines of code that differ between the cell above and below. What do these lines of code do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2lE915VxAWSG"
   },
   "outputs": [],
   "source": [
    "# Create a map or plot with two data layers\n",
    "\n",
    "#Experiment! What happens if you remove ax=ax1 from coastlines.plot() and cities.plot()?\n",
    "\n",
    "f, ax1 = plt.subplots(figsize=(10, 6))\n",
    "coastlines.plot(ax=ax1,\n",
    "                color=\"black\")\n",
    "cities.plot(ax=ax1)\n",
    "\n",
    "# Add a title\n",
    "ax1.set(title=\"Map of Cities and Global Lines\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PJNsynPYAWSG"
   },
   "source": [
    "Learn more about custom plotting in Python:\n",
    "\n",
    "https://www.earthdatascience.org/courses/scientists-guide-to-plotting-data-in-python/plot-spatial-data/customize-vector-plots/python-customize-map-legends-geopandas/\n",
    "\n",
    "https://geopandas.org/gallery/plotting_with_geoplot.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nZqRAA7CAWSH"
   },
   "source": [
    "### TASK 2\n",
    "Using the resources above, create a map that contains:\n",
    "1. Coastal lines (black)\n",
    "2. Cities, excluding megacities (points), with a color scale for pop_max\n",
    "3. Megacities (large black points)\n",
    "3. A legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wKAakadnAWSH"
   },
   "outputs": [],
   "source": [
    "# Format and plot your results from task 2\n",
    "# hint:\n",
    "?cities.plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RvqqbRFfAWSI"
   },
   "source": [
    "### Geoprocessing Vector Data Geoprocessing in Python: Clip Data\n",
    "Sometimes you have spatial data for a larger area than you need to process. For example you may be working on a project for your state or country. But perhaps you have data for the entire globe.\n",
    "\n",
    "You can clip the data spatially to another boundary to make it smaller. Once the data are clipped, your processing operations will be faster. It will also make creating maps of your study area easier and cleaner.\n",
    "\n",
    "In this workflow, you'll subset your cities data to only look at counties in the United States. First, we'll import a dataset of global political boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SBQLJxdoAWSJ"
   },
   "outputs": [],
   "source": [
    "country_data_url = \"https://naturalearth.s3.amazonaws.com/50m_cultural/ne_50m_admin_0_countries.zip\"\n",
    "et.data.get_data(url=country_data_url)\n",
    "\n",
    "# Create a path to the countries shapefile\n",
    "countries_path = os.path.join(\"data\", \"earthpy-downloads\",\n",
    "                              \"ne_50m_admin_0_countries\",\n",
    "                              \"ne_50m_admin_0_countries.shp\")\n",
    "\n",
    "# Read in the countries shapefile as GeoPandas dataframe\n",
    "countries = gpd.read_file(countries_path)\n",
    "\n",
    "# View attribute table:\n",
    "countries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UlWM-PnWAWSJ"
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(10, 6))\n",
    "countries.plot(ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "46TuC7lPAWSK"
   },
   "source": [
    "### Next, we'll use built-in pandas funcitonality to subset the shapefile to just the US boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WMmfKI3TAWSK"
   },
   "outputs": [],
   "source": [
    "# Subset the countries data to just a single country\n",
    "united_states_boundary = countries.loc[countries['SOVEREIGNT']\n",
    "                                       == 'United States of America']\n",
    "\n",
    "# Notice in the plot below, that only the boundary for the USA is in the new variable\n",
    "f, ax = plt.subplots(figsize=(10, 6))\n",
    "united_states_boundary.plot(ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sz7Xo5MWAWSL"
   },
   "source": [
    "### Now, we'll subset the cities layer to include only records which overlap in space with the united_states_boundary layer (aka are in the United States)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EiVaflFIAWSL"
   },
   "outputs": [],
   "source": [
    "# Clip the cities data to the USA boundary\n",
    "# Note -- this operation may take some time to run - be patient\n",
    "cities_in_usa = gpd.clip(cities, united_states_boundary)\n",
    "\n",
    "# Plot your final clipped data\n",
    "f, ax = plt.subplots()\n",
    "cities_in_usa.plot(ax=ax)\n",
    "ax.set(title=\"Cities clipped to the USA Boundary\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9s4e3Ll4cSPn"
   },
   "source": [
    "## TASK 3: How many cities are in the United States?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5cfuchoecP6T"
   },
   "outputs": [],
   "source": [
    "# Task 3 code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vC497LtLAWSM"
   },
   "source": [
    "## TASK 4: What is the largest city in the United States? What is the population of that city?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nXb-CVCjAWSM"
   },
   "outputs": [],
   "source": [
    "#Task 4 code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CUH9oYodc47X"
   },
   "source": [
    "## Merging vector data in geopandas\n",
    "One of our primary goals using geographic information systems (GIS) software in Environmental Data Science is to collocate information from different sources into a single analaysis-ready dataset. When we're working with vector data, this often means adding new columns to a geopandas dataframe containing values from another dataset.\n",
    "\n",
    "There are two ways to combine datasets in geopandas – attribute joins and spatial joins. [From Geopandas.org](https://geopandas.org/en/v0.8.2/mergingdata.html)\n",
    "\n",
    "*   **Attribute joins:** a GeoSeries or GeoDataFrame is combined with a regular pandas Series or DataFrame based on a common variable. This is analogous to normal merging or joining in pandas.\n",
    "\n",
    "*   **Spatial joins:** a Spatial Join, observations from two GeoSeries or GeoDataFrames are combined based on their spatial relationship to one another.Indented block\n",
    "\n",
    "First, we'll bring in another dataset of countries:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hqofNW42cmkI"
   },
   "outputs": [],
   "source": [
    "# read in country shapefile from the geopandas datasets collection\n",
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "print(world)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Lbpg8J2gZTW"
   },
   "source": [
    "Let's say we want to add the \"continent\" field (column) in the world geodataframe to the cities dataframe. Using an attribute join, we first find two columns that contain the same values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vNJfea09gVcV"
   },
   "outputs": [],
   "source": [
    "print(sorted(world.iso_a3.unique()))\n",
    "print(sorted(cities.sov_a3.unique()))\n",
    "print(\"There are \" + str(len(world.iso_a3.unique()))+ \" unique country codes in the world dataset\")\n",
    "print(\"There are \" + str(len(cities.sov_a3.unique()))+ \" unique country codes in the city dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BSyYd4DIkpyt"
   },
   "source": [
    "We do not have continent data for all of the countries represented in the city database, but we have some!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SEtpsbkvkncQ"
   },
   "outputs": [],
   "source": [
    "# First, we'll make a new pandas dataframe containing only the  iso_a3, and continent information:\n",
    "continents = world[['iso_a3', 'continent']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yVRmCKVQkQFW"
   },
   "outputs": [],
   "source": [
    "# Then, we'll merge this data to the cities dataset:\n",
    "cities = cities.merge(continents, left_on='sov_a3', right_on='iso_a3')\n",
    "\n",
    "# Is cities still a geopandas dataframe?\n",
    "type(cities)\n",
    "\n",
    "#On what continents do we have cities?\n",
    "cities.continent.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KFSeBixZmB9c"
   },
   "source": [
    "A spatial join involves fusing two datasets based on the euclidian distances calculated between feature locations.\n",
    "\n",
    "\n",
    "Sjoin Arguments\n",
    "\n",
    "`sjoin()` has two core arguments: how and op.\n",
    "\n",
    "**op**\n",
    "\n",
    "The op argument specifies how geopandas decides whether or not to join the attributes of one object to another. There are three different join options as follows:\n",
    "\n",
    "    intersects: The attributes will be joined if the boundary and interior of the object intersect in any way with the boundary and/or interior of the other object.\n",
    "\n",
    "    within: The attributes will be joined if the object’s boundary and interior intersect only with the interior of the other object (not its boundary or exterior).\n",
    "\n",
    "    contains: The attributes will be joined if the object’s interior contains the boundary and interior of the other object and their boundaries do not touch at all.\n",
    "\n",
    "You can read more about each join type in the Shapely documentation.\n",
    "\n",
    "**how**\n",
    "\n",
    "The how argument specifies the type of join that will occur and which geometry is retained in the resultant geodataframe. It accepts the following options:\n",
    "\n",
    "    left: use the index from the first (or left_df) geodataframe that you provide to sjoin; retain only the left_df geometry column\n",
    "\n",
    "    right: use index from second (or right_df); retain only the right_df geometry column\n",
    "\n",
    "    inner: use intersection of index values from both geodataframes; retain only the left_df geometry column\n",
    "\n",
    "Note more complicated spatial relationships can be studied by combining geometric operations with spatial join. To find all polygons within a given distance of a point, for example, one can first use the buffer method to expand each point into a circle of appropriate radius, then intersect those buffered circles with the polygons in question.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ptYDRH6mBnf"
   },
   "outputs": [],
   "source": [
    "# Create a countries shapefile with only one attribute (column), called 'name':\n",
    "countries = world[['geometry', 'name']]\n",
    "countries.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q87DNaF4nCHK"
   },
   "outputs": [],
   "source": [
    "# Recall all the attributes of cities:\n",
    "cities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bszSgKS-nGOS"
   },
   "outputs": [],
   "source": [
    "# Check and see if the merge worked\n",
    "cities_with_country = gpd.sjoin(cities, countries, how=\"inner\", op='intersects')\n",
    "cities_with_country.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IRdwL71Xs6MR"
   },
   "source": [
    "## TASK 5:\n",
    "In this markdown cell in your own words, explain how the spatial join worked. How does this differ from the attribute join?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FRn005lstNno"
   },
   "source": [
    "## Nested features\n",
    "Often, vector spatial features will be nested within each other. For example, in the world dataset, there are countries which are nested within continents.\n",
    "\n",
    "If you wanted to extract just the continent outlines, you would need to erase the country boundaries within each continent. We can use the **dissolve** function to do this.\n",
    "\n",
    "In a non-spatial setting, when all we need are summary statistics of the data, we aggregate our data using the `groupby` function. But for spatial data, we sometimes alsoIn a non-spatial setting, when all we need are summary statistics of the data, we aggregate our data using the groupby function. But for spatial data, we sometimes also need to aggregate geometric features. In the geopandas library, we can aggregate geometric features using the dissolve function.\n",
    "\n",
    "dissolve can be thought of as doing three things: (a) it dissolves all the geometries within a given group together into a single geometric feature (using the unary_union method), and (b) it aggregates all the rows of data in a group using groupby.aggregate(), and (c) it combines those two results.\n",
    "\n",
    "```\n",
    "# This is formatted as code\n",
    "```\n",
    "\n",
    " need to aggregate geometric features. In the geopandas library, we can aggregate geometric features using the `dissolve` function.\n",
    "\n",
    "`dissolve` can be thought of as doing three things: (a) it dissolves all the geometries within a given group together into a single geometric feature (using the unary_union method), and (b) it aggregates all the rows of data in a group using `groupby.aggregate()`, and (c) it combines those two results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oZZ6er1Et_XP"
   },
   "outputs": [],
   "source": [
    "world = world[['continent', 'geometry']]\n",
    "\n",
    "continents = world.dissolve(by='continent')\n",
    "\n",
    "continents.plot();\n",
    "\n",
    "continents.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pna_Qn2aurYI"
   },
   "source": [
    "If we are interested in aggregate populations, however, we can pass different functions to the dissolve method to aggregate populations using the `aggfunc = ` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IbG_sgdiuyX5"
   },
   "outputs": [],
   "source": [
    "# Re-read in the world dataset\n",
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "\n",
    "# Select only the attributes we're interested in:\n",
    "world = world[['continent', 'geometry', 'pop_est']]\n",
    "\n",
    "# Dissolve into country aggregates, collecting the sum of other attributes\n",
    "continents = world.dissolve(by='continent', aggfunc='sum')\n",
    "\n",
    "continents.plot(column = 'pop_est', scheme='quantiles', cmap='YlOrRd');\n",
    "continents.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ILJ15rlfvjRX"
   },
   "source": [
    "## TASK 6-8: putting it together\n",
    "Use your skills with `merge`, `dissolve`, and pandas math to do the following:\n",
    "6. What is the total urban population on each continent? Show your results as a chloropleth map and a table.\n",
    "7. What fraction of the total population lives in cities in each continent? Show your results as a chloropleth map and a table.\n",
    "8. What is the most urban continent on earth (largest share of the population lives in cities)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ij3UEmxqvNwW"
   },
   "outputs": [],
   "source": [
    " # Task 6 code here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Xzpz9CCwc2S"
   },
   "outputs": [],
   "source": [
    "# Task 6 code here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G-FlMvOnwgdF"
   },
   "outputs": [],
   "source": [
    "# Task 8 code here:"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
